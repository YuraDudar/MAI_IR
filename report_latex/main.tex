\documentclass[a4paper,14pt]{extarticle}

% --- Подключение пакетов ---
\usepackage{float}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{csquotes} % Для команды \enquote

% Шрифты Times New Roman
\usepackage{tempora} 
\usepackage{newtxmath}

% --- Геометрия страницы (ГОСТ) ---
\usepackage{geometry}
\geometry{
    left=3cm,
    right=1cm,
    top=2cm,
    bottom=2cm
}

% --- Интервалы и отступы ---
\usepackage{setspace}
\onehalfspacing % Полуторный интервал
\usepackage{indentfirst} % Красная строка
\setlength{\parindent}{1.25cm}

% --- Графика и код ---
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage[labelsep=endash]{caption} 
\captionsetup{justification=centering}

% --- Настройка колонтитулов (Номер страницы справа сверху) ---
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{} 
\fancyhead[R]{\thepage} 
\renewcommand{\headrulewidth}{0pt}

% --- Гиперссылки ---
\usepackage[hidelinks]{hyperref}

\begin{document}

% ================= ТИТУЛЬНЫЙ ЛИСТ =================
\begin{titlepage}
\begin{center}
\bfseries

{\Large Московский авиационный институт\\ (национальный исследовательский университет)

}

\vspace{48pt}

{\large Факультет информационных технологий и прикладной математики
}

\vspace{36pt}

{\large Кафедра вычислительной математики и~программирования

}


\vspace{48pt}

Лабораторные работы по курсу \enquote{Информационный поиск}

\end{center}

\vspace{72pt}

\begin{flushright}
\begin{tabular}{rl}
Студент: & Ю.\,М. Дударь \\
Преподаватель: & А.\,А. Кухтичев \\
Группа: & М8О-409Б-22 \\
Дата: & \\
Оценка: & \\
Подпись: & \\
\end{tabular}
\end{flushright}

\vfill

\begin{center}
\bfseries
Москва, \the\year
\end{center}
\end{titlepage}

\pagebreak
% ==================================================

% Оглавление
\tableofcontents
\newpage

% --- Основной контент ---

\section{Лабораторная работа №1. Добыча корпуса документов}
\subsection{Задание}
Необходимо проанализировать корпус документов, который будет использован при выполнении остальных лабораторных работ.

\textbf{Основные этапы работы:}
\begin{enumerate}
    \item \textbf{Сбор данных.} Скачать примеры документов к себе на компьютер. В отчёте указать источник данных. Источников в итоговом индексе должно быть не менее двух.
    \item \textbf{Анализ корпуса.} Ознакомиться с документами, изучить их характеристики:
    \begin{itemize}
        \item Из чего состоит текст?
        \item Есть ли дополнительная мета-информация?
        \item Если есть разметка текста, то какая она?
    \end{itemize}
    \item \textbf{Выделение текста.} Реализовать очистку документов от разметки (HTML-тегов, скриптов) для получения «чистого» текста.
    \item \textbf{Поиск аналогов.} Найти существующие поисковые системы, которые уже можно использовать для поиска по выбранному набору документов (например, встроенный поиск сайта-источника или поиск Google с использованием ограничений на URL или на сайт). 
    \textit{Примечание: Если такого поиска найти невозможно, то использовать данный корпус для выполнения лабораторных работ нельзя!}
    \item \textbf{Сравнительный анализ.} Привести несколько примеров запросов к существующим поисковикам, указать недостатки в полученной поисковой выдаче.
\end{enumerate}

\textbf{В результатах работы должна быть указана статистическая информация о корпусе:}
\begin{itemize}
    \item Размер примеров «сырых» документов (Raw Data).
    \item Общее количество документов.
    \item Размер текста, выделенного из «сырых» данных (Clean Text).
    \item Средний размер документа и средний объём текста в документе.
\end{itemize}

\subsection{Краткое описание метода решения задачи}

Для формирования корпуса документов была выбрана стратегия тематического краулинга новостных ресурсов. Основная задача заключалась в сборе текстовых данных на русском языке, обладающих достаточным объемом и разнообразием верстки.

\textbf{Выбор источников данных:}
\begin{enumerate}
    \item \textbf{Первоначальный выбор (отклонен):} \textit{Forbes.ru}. 
    В ходе предварительного анализа было выявлено, что данный ресурс активно использует технологии динамической подгрузки контента (AJAX/Single Page Application) и сложные механизмы защиты от автоматического сбора данных. Парсинг такого ресурса требует использования инструментов эмуляции браузера (Selenium, Puppeteer), значительно замедляет процесс сбора и избыточно для целей лабораторной работы. От использования данного источника было решено отказаться.
    
    \item \textbf{Итоговый выбор:}
    \begin{itemize}
        \item \textit{Consultant.ru (Раздел Legal News)} — выбран как пример строго структурированного ресурса с юридической лексикой.
        \item \textit{Business.ru (Раздел News)} — выбран как пример современного коммерческого медиа-ресурса с большим количеством рекламы, скриптов и сложной DOM-структурой.
    \end{itemize}
\end{enumerate}

\textbf{Существующие поисковые системы:}
Для поиска по выбранным ресурсам можно использовать глобальную поисковую систему Google с оператором ограничения по домену (например, \texttt{site:consultant.ru запрос}). 
\begin{itemize}
    \item \textbf{Достоинства:} Высокая скорость, качественное ранжирование, поддержка морфологии.
    \item \textbf{Недостатки:} Невозможность настройки алгоритма ранжирования под специфические нужды, наличие рекламы в выдаче, ограничения на автоматические запросы (CAPTCHA).
\end{itemize}

\subsection{Характеристики корпуса и разметка}

В ходе анализа скачанных документов были изучены их структура и мета-данные.

\textbf{Общая характеристика:}
Текст представлен в формате HTML 5. Кодировка файлов — UTF-8.

\textbf{1. Источник Consultant.ru:}
\begin{itemize}
    \item \textbf{Структура текста:} HTML-код относительно «чистый», используется семантическая верстка. Основной контент заключен в предсказуемые контейнеры.
    \item \textbf{Мета-информация:} Присутствуют стандартные технические теги (\texttt{viewport}, \texttt{csrf-token}, \texttt{X-UA-Compatible}). Семантическая микроразметка (Schema.org) выражена слабо.
    \item \textbf{Зашумленность:} В текстовые узлы попадают элементы навигации («Главное», «Все новости») и служебные даты публикации.
\end{itemize}

\textbf{2. Источник Business.ru:}
\begin{itemize}
    \item \textbf{Структура текста:} Верстка сложная, перегруженная вложенными блоками (\texttt{div}). 
    \item \textbf{Мета-информация:} Богатая мета-разметка. Активно используется протокол \textbf{Open Graph} (\texttt{og:title}, \texttt{og:description}, \texttt{og:image}), позволяет эффективно извлекать заголовки и аннотации.
    \item \textbf{Зашумленность:} Высокая. Страницы перегружены JavaScript-кодом рекламных сетей (AdRiver, Yandex Ads, Mail.ru sync). В «чистый текст» при наивной очистке попадают Pop-up окна («Регистрация за минуту»), призывы к действию (CTA) и маркетинговые вставки.
\end{itemize}

\textbf{Ответы на вопросы задания:}
\begin{enumerate}
    \item \textbf{Из чего состоит текст?} Текст состоит из новостных статей юридической и деловой тематики, заголовков, дат публикаций, а также элементов интерфейса сайта (меню, футер, рекламные блоки).
    \item \textbf{Есть ли дополнительная мета-информация?} Да, используются мета-теги HTML и Open Graph для описания контента.
    \item \textbf{Какая разметка текста?} Стандартная HTML-разметка. Текст структурирован с помощью тегов параграфов (\texttt{<p>}), заголовков (\texttt{<h1>}-\texttt{<h3>}) и списков (\texttt{<ul>}).
\end{enumerate}

\subsection{Статистическая информация о корпусе}

Ниже приведены количественные характеристики собранного корпуса документов.

\begin{table}[h]
    \centering
    \caption{Статистика собранного корпуса документов}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{Параметр} & \textbf{Значение} \\ \hline
        Общее количество документов & 40 823 шт. \\ \hline
        --- Consultant.ru & 28 162 шт. \\ \hline
        --- Business.ru & 12 661 шт. \\ \hline
        Общий размер «сырых» данных (Raw HTML) & $\approx$ 9 507.04 МБ (9.28 ГБ) \\ \hline
        Общий размер выделенного текста (Clean Text) & 672.20 МБ \\ \hline
        Средний размер документа (HTML) & 238.47 КБ \\ \hline
        Средний объём чистого текста в документе & 16.86 КБ \\ \hline
        \textbf{Соотношение Text / HTML} & \textbf{7.07\%} \\ \hline
    \end{tabular}
\end{table}

\textbf{Анализ статистики:}
Средний размер HTML-документа (238 КБ) значительно превышает размер полезного текста (16 КБ). Соотношение полезной нагрузки к общему объему составляет всего 7.07\%. Это означает, что \textbf{93\% скачанных данных представляют собой «технический мусор»} (скрипты аналитики, стили, разметка верстки). Это накладывает жесткие требования к этапу токенизации и очистки данных в следующих лабораторных работах.

\subsection{Изображения}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{сайты.png}
    \caption{Пример поисковой системы Яндекса для выбранных сайтов}
    \label{fig:site}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{пример_текста_сайта.png}
    \caption{Пример текста сайта}
    \label{fig:siteex}
\end{figure}

\subsection{Выводы}
Собранный корпус документов признан пригодным для выполнения цикла лабораторных работ по следующим причинам:
\begin{enumerate}
    \item \textbf{Объем:} Количество документов (>40 000) достаточно для построения репрезентативного индекса и анализа закона Ципфа.
    \item \textbf{Разнообразие:} Корпус содержит два независимых источника с принципиально разной структурой (строгий юридический портал и зашумленный коммерческий сайт).
    \item \textbf{Реалистичность:} Данные представляют собой реальный веб-контент.
\end{enumerate}



\newpage
\section{Лабораторная работа №2. Поисковый робот}

\subsection{Задание}
Необходимо разработать поискового робота (краулер) — программный компонент для автоматического сбора документов из сети Интернет.

\textbf{Требования к реализации:}
\begin{enumerate}
    \item \textbf{Реализация парсера.} Написать компоненты обкачки документов, используя любой язык программирования.
    
    \item \textbf{Конфигурация.} Единственным аргументом при запуске поискового робота должен быть путь до конфигурационного файла в формате YAML, содержащего:
    \begin{itemize}
        \item Секцию \texttt{db} — параметры подключения к базе данных;
        \item Секцию \texttt{logic} — настройки логики робота (например, задержка между запросами к страницам);
        \item Иные данные, необходимые для работы алгоритма.
    \end{itemize}
    
    \item \textbf{Хранение данных.} Необходимо сохранять собранные документы в базу данных (например, MongoDB или PostgreSQL) со следующей структурой полей:
    \begin{itemize}
        \item \texttt{url} — нормализованный URL документа;
        \item \texttt{raw\_html} — «сырой» HTML-текст документа;
        \item \texttt{source\_name} — название источника данных;
        \item \texttt{crawled\_at} — дата и время обкачки в формате Unix timestamp.
    \end{itemize}
    
    \item \textbf{Возобновляемость (Resumability).} Должна быть предусмотрена возможность остановки робота в любой момент времени. При повторном запуске процесс сбора данных должен продолжаться с того документа (или этапа), на котором он был остановлен.
    
    \item \textbf{Переобкачка (Re-crawl).} Робот должен обладать функционалом периодической проверки уже существующих в базе документов и их обновления в случае изменения контента.
\end{enumerate}

\subsection{Описание метода решения задачи}

Для реализации поискового робота (краулера) был выбран язык программирования \textbf{Python}. Данный выбор обусловлен наличием развитой экосистемы библиотек для работы с сетью и парсинга HTML, а также тем, что задача сбора данных является I/O-bound (зависящей от скорости ввода-вывода), где производительность интерпретируемого языка не является узким местом.

В качестве хранилища данных выбрана реляционная СУБД \textbf{PostgreSQL}. В отличие от NoSQL решений, она обеспечивает строгую схему данных и транзакционную целостность важно для предотвращения дублирования документов. Для удобства развертывания окружение базы данных контейнеризировано с помощью \textbf{Docker}.

\subsubsection{Структура проекта}
Разработка велась с соблюдением принципов модульности. Кодовая база разделена на логические компоненты, вынесенные в пакет \texttt{src}.

\textbf{Файловая структура:}
\begin{itemize}
    \item \texttt{config.yaml} — конфигурационный файл. Содержит параметры подключения к БД, настройки задержек (delay), User-Agent и список источников с их CSS-селекторами.
    \item \texttt{main.py} — точка входа. Отвечает за инициализацию зависимостей, чтение конфигурации и запуск основного цикла краулера.
    \item \texttt{src/database.py} — слой доступа к данным (DAL). Инкапсулирует логику работы с библиотекой \texttt{psycopg2}, управляет соединениями и транзакциями.
    \item \texttt{src/parser.py} — модуль синтаксического анализа. Использует библиотеку \texttt{BeautifulSoup4} для построения DOM-дерева и извлечения ссылок на основе CSS-селекторов, заданных в конфиге.
    \item \texttt{src/crawler.py} — ядро системы. Реализует бизнес-логику обхода страниц, управление очередью ссылок, соблюдение этикета (паузы) и обработку сетевых ошибок.
\end{itemize}

\subsubsection{Схема базы данных}
Для хранения собранной информации была спроектирована таблица \texttt{documents}. Ключевой особенностью является использование хеширования для быстрой проверки существования документа.

\begin{itemize}
    \item \texttt{id} (SERIAL PRIMARY KEY) — уникальный идентификатор.
    \item \texttt{url} (TEXT) — нормализованный URL документа.
    \item \texttt{url\_hash} (VARCHAR(64)) — MD5-хеш от нормализованного URL. По этому полю построен уникальный индекс, что позволяет выполнять проверку наличия документа за $O(1)$.
    \item \texttt{source\_name} (VARCHAR) — метка источника (например, 'consultant').
    \item \texttt{raw\_html} (TEXT) — полный HTML-код страницы.
    \item \texttt{crawled\_at} (BIGINT) — временная метка скачивания (Unix Timestamp).
\end{itemize}

\subsubsection{Алгоритм работы краулера}
Логика робота построена на принципе итеративного погружения и обеспечивает требование возобновляемости без использования сложных очередей.

\textbf{1. Инициализация и настройка:}
При запуске робот загружает параметры из \texttt{config.yaml}. Для сетевого взаимодействия создается сессия (\texttt{requests.Session}) даетпереиспользовать TCP-соединения (Keep-Alive) и имитировать поведение реального браузера через заголовки (User-Agent, Referer).

\textbf{2. Стратегия обхода:}
Робот обрабатывает источники последовательно. Для каждого источника запускается цикл пагинации:
\begin{enumerate}
    \item Скачивается страница листинга (списка новостей).
    \item Парсер извлекает ссылки на статьи и ссылку на следующую страницу.
    \item Для каждой найденной ссылки выполняется процедура \textbf{дедупликации}:
    \begin{itemize}
        \item URL нормализуется (приводится к нижнему регистру, удаляются лишние слеши).
        \item Вычисляется MD5-хеш.
        \item Выполняется запрос к БД: \texttt{SELECT 1 FROM documents WHERE url\_hash = ?}.
        \item Если документ существует, он пропускается. Если нет — происходит скачивание.
    \end{itemize}
\end{enumerate}

Проверка наличия URL в базе перед скачиванием позволяет останавливать и перезапускать робот в любой момент. При повторном запуске он быстро пропустит уже скачанные страницы и продолжит работу с места остановки.

\textbf{3. Обработка ошибок и Anti-Ban:}
Реализован механизм надежного скачивания (\texttt{Retry Logic}). В случае возникновения сетевой ошибки или получения статусов 5xx, робот делает паузу и повторяет попытку до 3-х раз с экспоненциальным увеличением интервала ожидания. Также внедрена проверка на наличие CAPTCHA или блокировок (код 403) — в этом случае работа приостанавливается на длительное время для «остывания».

\textbf{4. Парсинг контента:}
Для обеспечения универсальности, логика извлечения данных вынесена в конфигурационный файл. Для каждого сайта задаются CSS-селекторы контейнеров новостей и элементов пагинации. 

\subsection{Журнал выполнения задания}

В процессе реализации и отладки поискового робота возник ряд технических проблем, связанных со спецификой целевых сайтов и требованиями к надежности системы. Ниже описаны ключевые трудности и способы их устранения.

\begin{enumerate}
    \item \textbf{Проблема: Агрессивная защита от ботов (Consultant.ru).}
    При первых запусках сервер источника \textit{Consultant.ru} возвращал ошибку HTTP 403 (Forbidden) уже после 5–10 запросов. Стандартных заголовков библиотеки \texttt{requests} было недостаточно для прохождения фильтров безопасности.
    
    \textbf{Решение:}
    \begin{itemize}
        \item Внедрен расширенный набор HTTP-заголовков (\texttt{User-Agent}, \texttt{Accept}, \texttt{Referer}), полностью имитирующий поведение современного браузера.
        \item Реализована система вежливой обкачки: между запросами добавлена искусственная задержка (Delay), к которой добавляется случайная величина (Jitter) для предотвращения обнаружения робота по строгой периодичности запросов.
        \item Добавлен программный детектор блокировок: при обнаружении ключевых слов «captcha» или «доступ ограничен» робот автоматически приостанавливает работу на длительное время.
    \end{itemize}

    \item \textbf{Проблема: Различная логика пагинации.}
    Источники имеют принципиально разную структуру навигации: \textit{Consultant.ru} использует GET-параметры (\texttt{?page=N}), а \textit{Business.ru} — ссылки на хронологически предыдущие страницы, которые невозможно предсказать аналитически.
    
    \textbf{Решение:}
    Парсер был спроектирован как универсальный конечный автомат. Вместо жесткого цикла по номерам страниц, реализован поиск элемента «Следующая страница» в DOM-дереве на основе CSS-селектора, указанного в конфигурационном файле. Это позволило использовать один и тот же код для обоих сайтов.

    \item \textbf{Проблема: Дублирование данных при перезапуске.}
    Требование о возможности остановки и продолжения работы робота создавало риск повторного скачивания одних и тех же документов, что увеличивало нагрузку на сеть и базу данных.
    
    \textbf{Решение:}
    В базу данных добавлено поле \texttt{url\_hash} (MD5 от нормализованного URL) с уникальным индексом. В логику робота внедрена предварительная проверка (Pre-check): перед выполнением HTTP-запроса вычисляется хеш ссылки и проверяется его наличие в БД. Если документ уже существует, скачивание пропускается.

    \item \textbf{Проблема: Нестабильность сетевого соединения.}
    При длительном сборе данных (более 10 000 страниц) неизбежно возникали ошибки \texttt{ConnectionTimeout} и \texttt{ConnectionReset}, которые приводили к аварийной остановке скрипта.
    
    \textbf{Решение:}
    Реализован механизм повторных попыток (Retry Policy). Сетевые операции обернуты в цикл, который предпринимает до 3 попыток выполнения запроса с экспоненциально возрастающей задержкой перед тем, как окончательно пометить страницу как недоступную.
\end{enumerate}

\subsection{План тестирования}

Для проверки корректности работы поискового робота была разработана методика функционального тестирования, покрывающая основные требования технического задания.

\textbf{Тест-кейс №1. Проверка конфигурации и подключения к БД.}
\begin{itemize}
    \item \textbf{Действие:} Запуск контейнера с базой данных (\texttt{docker-compose up}) и запуск скрипта с некорректными учетными данными в \texttt{config.yaml}.
    \item \textbf{Ожидаемый результат:} Скрипт должен корректно обработать исключение подключения и вывести понятное сообщение об ошибке в лог, не завершаясь аварийно (traceback).
    \item \textbf{Результат:} Тест пройден. Логирование ошибок настроен корректно.
\end{itemize}

\textbf{Тест-кейс №2. Валидация парсинга и сохранения данных.}
\begin{itemize}
    \item \textbf{Действие:} Запуск робота на ограниченное количество страниц (50 шт.). Проверка содержимого таблицы \texttt{documents} в PostgreSQL.
    \item \textbf{Ожидаемый результат:} В базе должно появиться ровно 50 записей. Поле \texttt{raw\_html} не должно быть пустым. URL должны быть нормализованы (отсутствие UTM-меток).
    \item \textbf{Результат:} Тест пройден. Данные сохраняются корректно, HTML-код валиден.
\end{itemize}

\textbf{Тест-кейс №3. Проверка возобновляемости.}
\begin{itemize}
    \item \textbf{Действие:} 
    1. Запустить робота.
    2. Принудительно остановить процесс (Ctrl+C) после скачивания 20 документов.
    3. Повторно запустить робота.
    \item \textbf{Ожидаемый результат:} Робот должен начать сканирование списка ссылок, обнаруживать, что первые 20 документов уже есть в базе (по хешу), писать в лог сообщение о пропуске (\texttt{Skipping...}) и не дублировать записи в БД. Скачивание новых документов должно продолжиться с 21-го.
    \item \textbf{Результат:} Тест пройден. Механизм дедупликации работает корректно, дубликаты в БД отсутствуют.
\end{itemize}

\textbf{Тест-кейс №4. Работа под нагрузкой и Anti-Ban.}
\begin{itemize}
    \item \textbf{Действие:} Длительный запуск (обход 1000+ страниц) с установленной задержкой 2 секунды.
    \item \textbf{Ожидаемый результат:} Отсутствие блокировок (HTTP 403) со стороны целевого сайта. Стабильное потребление памяти процессом.
    \item \textbf{Результат:} Тест пройден. Имитация User-Agent и случайные задержки позволили обойти защиту \textit{Consultant.ru}.
\end{itemize}

\subsection{Изображения}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{лги_краулера.png}
    \caption{Пример логов краулера при обкачке сайтов}
    \label{fig:crauler}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{база_обкаченных_сайтов.png}
    \caption{Заполненная база данных}
    \label{fig:db}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{количество_строк.png}
    \caption{Количество строк в базе данных}
    \label{fig:dbk}
\end{figure}


\subsection{Выводы}

В ходе выполнения лабораторной работы был разработан и успешно протестирован поисковый робот для сбора корпуса документов. 

\textbf{Достигнутые результаты:}
\begin{enumerate}
    \item Создан универсальный парсер на языке Python, способный обрабатывать различные новостные ресурсы благодаря конфигурации селекторов через YAML.
    \item Реализована надежная архитектура хранения данных на базе PostgreSQL, обеспечивающая целостность данных и защиту от дубликатов.
    \item Выполнено требование возобновляемости сбора данных, что критически важно при работе с большими объемами информации и нестабильным соединением.
    \item Сформирован корпус из более чем 40 000 документов, который будет использован в следующих лабораторных работах.
\end{enumerate}

\textbf{Критический анализ и недостатки:}
\begin{itemize}
    \item \textbf{Синхронная архитектура.} Текущая реализация использует библиотеку \texttt{requests}, которая блокирует поток выполнения на время ожидания ответа сервера. При масштабировании до миллионов документов это станет узким местом. 
    \textit{Путь решения:} Переход на асинхронный стек (\texttt{aiohttp}, \texttt{asyncio}), что позволит обрабатывать сотни запросов параллельно.
    
    \item \textbf{Хранение HTML в БД.} Сохранение полного текста HTML («сырых» данных) непосредственно в реляционную базу данных увеличивает её объем и нагрузку на I/O.
    \textit{Путь решения:} Использование объектного хранилища (S3-compatible) для «сырых» файлов, оставляя в БД только метаданные и ссылки. Либо использование сжатия (gzip) перед записью в базу.
    
    \item \textbf{Жесткая привязка к верстке.} Логика парсинга зависит от CSS-классов. Если владелец сайта изменит верстку, робот перестанет работать.
    \textit{Путь решения:} Это фундаментальная проблема веб-скрейпинга, решаемая внедрением мониторинга качества данных (alerting при пустых результатах).
\end{itemize}

\newpage
\section{Лабораторная работа №3. Токенизация и закон Ципфа}

\subsection{Задание}
Целью работы является реализация базовых компонентов лингвистического анализа текста и исследование статистических закономерностей естественного языка на собранном корпусе документов.

\textbf{1. Токенизация}
\begin{itemize}
    \item Реализовать процесс разбиения текстов документов на токены (слова), который будет использоваться при индексации.
    \item Выработать и описать правила деления текста на токены. В отчете указать достоинства и недостатки выбранного метода.
    \item Привести примеры токенов, которые были выделены неудачно (ошибки токенизации), и предложить способы доработки правил для устранения этих проблем.
\end{itemize}

\textbf{В результатах работы должна быть указана следующая статистика:}
\begin{itemize}
    \item Общее количество токенов в корпусе.
    \item Средняя длина токена (в байтах или символах).
    \item Время выполнения программы и зависимость времени от объёма входных данных.
    \item Скорость токенизации в расчёте на килобайт входного текста.
    \item Анализ производительности: является ли скорость оптимальной и способы её ускорения.
\end{itemize}

\textbf{2. Закон Ципфа}
\begin{itemize}
    \item Для собранного корпуса построить график распределения терминов по частотам в логарифмической шкале.
    \item Наложить на этот график теоретическую кривую закона Ципфа.
    \item Провести анализ и объяснить причины расхождения реальных данных с теоретической моделью.
    \item \textit{(Дополнительно)} Подобрать константы для закона Мандельброта и наложить полученный график на распределение частот.
\end{itemize}

\textbf{3. Лемматизация / Стемминг}
\begin{itemize}
    \item Добавить в поисковую систему модуль нормализации слов (стемминг или лемматизацию).
    \item Провести оценку качества поиска после внедрения морфологического анализа. Сравнить результаты с точным поиском по словоформам.
    \item Изучить запросы, где качество поиска ухудшилось, объяснить причины и предложить варианты решения.
\end{itemize}

\subsection{Краткое описание метода решения задачи}

Реализация лабораторной работы была разделена на два этапа: подготовка данных (экспорт из БД) и разработка высокопроизводительного аналитического ядра на языке C++.

\subsubsection{Подготовка данных (Python)}
Поскольку в предыдущей работе документы сохранялись в базу данных PostgreSQL в виде «сырого» HTML, первым шагом стала их очистка. Был разработан скрипт \texttt{export\_corpus.py}, который:
\begin{itemize}
    \item Использует библиотеку \texttt{BeautifulSoup4} для удаления HTML-тегов, скриптов (\texttt{<script>}) и стилей.
    \item Сохраняет очищенный текст.
\end{itemize}
В результате был получен чистый корпус, пригодный для обработки на C++.

\subsubsection{Архитектура C++ приложения}
Основная часть работы выполнена на языке C++ с соблюдением требования об ограничении использования STL (запрет на \texttt{std::map}, \texttt{std::unordered\_map} для хранения словаря).

\textbf{Реализованные компоненты:}

\begin{enumerate}
    \item \textbf{Собственная Хеш-таблица (\texttt{src/custom\_map.hpp}).}
    Для хранения частотного словаря (Терм $\rightarrow$ Частота) была реализована структура данных на основе метода цепочек. 
    \begin{itemize}
        \item В качестве основы используется \texttt{std::vector} корзин.
        \item Хеш-функция: модифицированный алгоритм djb2 сдвиги и сложение.
        \item Разрешение коллизий: связный список внутри корзины (реализован через вектор узлов).
    \end{itemize}

    \item \textbf{Токенизатор (\texttt{src/tokenizer.cpp}).}
    Модуль отвечает за чтение файлов и разбиение потока байтов на слова.
    \begin{itemize}
        \item \textbf{Работа с UTF-8:} Поскольку стандартный \texttt{char} в C++ — это 1 байт, а русские буквы в UTF-8 занимают 2 байта, реализована ручная обработка мультибайтовых последовательностей.
        \item \textbf{Нормализация:} Приведение к нижнему регистру выполняется путем проверки диапазонов байтов кириллицы (сдвиг кодов символов на \texttt{0x20} для диапазона А-П и Р-Я).
        \item \textbf{Фильтрация:} Знаки препинания и спецсимволы отбрасываются.
    \end{itemize}

    \item \textbf{Стеммер (\texttt{src/stemmer.cpp}).}
    Реализован стеммер Портера для русского языка. Алгоритм последовательно отсекает окончания (флексии) для приведения слова к псевдооснове.
    \begin{itemize}
        \item Используется для описания правил (удаление окончаний прилагательных, причастий, глаголов, существительных).
        \item Реализована защита от чрезмерного стемминга (не удалять окончания у слов короче 4 байт).
    \end{itemize}
\end{enumerate}

\subsection{Результаты и анализ производительности}

В ходе работы были проведены замеры производительности системы в различных режимах (Debug/Release) и с разной степенью обработки текста (с стеммингом и без).

\textbf{Исходные параметры корпуса:}
\begin{itemize}
    \item Количество файлов: 40 823 шт.
    \item Общий объем текстовых данных: 90.18 МБ.
\end{itemize}

\subsubsection{Сравнительная статистика}

\begin{table}[h]
    \centering
    \caption{Сравнение характеристик индекса до и после стемминга}
    \begin{tabular}{|l|c|c|}
        \hline
        \textbf{Параметр} & \textbf{Без стемминга} & \textbf{С стеммингом} \\ \hline
        Уникальные токены & 146 471 & 75 531 \\ \hline
        Общее кол-во токенов & 7 070 037 & 6 728 029 \\ \hline
        Средняя длина токена & 12.16 байт & 10.27 байт \\ \hline
        Время обработки & 3.86 сек & 131.29 сек \\ \hline
        Скорость обработки & \textbf{23 944.9 КБ/с} & \textbf{703.3 КБ/с} \\ \hline
    \end{tabular}
\end{table}

\textbf{Анализ результатов:}
\begin{enumerate}
    \item \textbf{Сокращение словаря.} Применение стемминга позволило сократить размер словаря на \textbf{48.5\%} (с 146 тыс. до 75 тыс. терминов). Это существенно оптимизирует размер будущего индекса и улучшает полноту поиска, объединяя словоформы.
    \item \textbf{Производительность.} 
    \begin{itemize}
        \item В режиме \textbf{«Без стемминга»} скорость составила $\approx$24 МБ/с. Это высокий показатель, эффективно собственной реализации хеш-таблицы и буферизированного чтения файлов.
        \item В режиме \textbf{«С стеммингом»} скорость упала до 0.7 МБ/с (в 34 раза). Компиляция и применение регулярных выражений для каждого из 7 млн слов — крайне ресурсоемкая операция. 
    \end{itemize}
\end{enumerate}

\subsection{Анализ закона Ципфа}

На основе полученных частотных данных был построен график распределения рангов и частот в логарифмическом масштабе (Log-Log Scale).

Как видно на рисунке \ref{fig:graf}, график демонстрирует классическую степенную зависимость $Frequency = \frac{C}{Rank^\alpha}$, характерную для естественных языков. Анализ поведения кривой позволяет выделить три зоны:

\textbf{1. Зона высоких частот («Голова», Rank < 10)}
В начале графика синяя линия (реальные данные) совпадает с теоретической. Это зона «стоп-слов» (союзы, предлоги: «и», «в», «на»), частота которых превышает $2 \cdot 10^5$. Их поведение полностью соответствует ожиданиям.

\textbf{2. Зона средних частот («Тело», 10 < Rank < 10 000)}
В этом диапазоне наблюдается «горб» — реальная кривая идет выше теоретической прямой. 
\textit{Причина:} Это характерно для специализированных корпусов (юридическая и деловая тематика). Специфические термины (например: «закон», «суд», «налог», «рубль», «организация») используются в текстах намного интенсивнее, чем в общелитературном языке, что насыщает текст и поднимает кривую вверх. Также влияние оказывают повторяющиеся элементы навигации сайтов.

\textbf{3. Зона низких частот («Хвост», Rank > 10 000)}
Наблюдается резкий спад, переходящий в ступенчатую структуру («лесенку»). Это зона редких слов.
\begin{itemize}
    \item Крутой наклон свидетельствует об ограниченности словарного запаса (около 75 тыс. стемм).
    \item «Ступеньки» в конце графика соответствуют дискретным частотам: 5, 4, 3, 2.
    \item Последняя, самая длинная ступень — это \textit{hapax legomena} (слова, встретившиеся ровно 1 раз).
\end{itemize}

\textbf{Вывод по графику:} Распределение валидно и подтверждает, что собранный корпус является естественным текстом, пригодным для задач информационного поиска. Отклонения объясняются предметной областью (новостной/юридический домен) и ограниченным размером выборки.

\subsection{Журнал выполнения задания}

В процессе разработки компонентов лингвистического анализа возник ряд нетривиальных проблем, связанных с особенностями языка C++ и требованиями к производительности.

\begin{enumerate}
    \item \textbf{Проблема: Обработка кодировки UTF-8 в C++.}
    Стандартный класс \texttt{std::string} в C++ оперирует байтами, а не символами. Русские буквы в кодировке UTF-8 занимают 2 байта (диапазон \texttt{0xD0-0xD1}). Стандартные функции \texttt{tolower()} из библиотеки \texttt{<cctype>} работают корректно только с ASCII (латиницей) и портят кириллицу.
    
    \textbf{Решение:} Реализован собственный алгоритм нормализации (\texttt{to\_lower\_utf8}). Он проходит по строке побайтово, определяет длину символа и, если обнаруживает байты из диапазона кириллицы, выполняет битовые сдвиги (смещение на \texttt{0x20} для младшего байта), корректно переводя заглавные буквы в строчные без использования внешних библиотек локализации (ICU).

    \item \textbf{Проблема: Запрет на использование STL Maps.}
    Техническое задание запрещало использование \texttt{std::map} и \texttt{std::unordered\_map}. Необходимо было создать эффективную структуру для хранения сотен тысяч уникальных токенов.
    
    \textbf{Решение:} Реализован класс \texttt{CustomMap} на основе хеш-таблицы с разрешением коллизий методом цепочек. В качестве базового контейнера использован \texttt{std::vector}, а хеш-функция реализована по алгоритму \texttt{djb2}, который обеспечивает хорошее распределение для строковых ключей. Это позволило добиться производительности вставки и поиска $O(1)$ в среднем случае.

    \item \textbf{Проблема: Агрессивный стемминг коротких слов.}
    Первая итерация стеммера использовала жадные регулярные выражения. Это приводило к ошибкам на коротких словах: например, слово «дом» (существительное) обрезалось до «д», так как окончание «ом» совпадало с правилом для творительного падежа (например, «стол-ом»).
    
    \textbf{Решение:} В логику замены добавлена эвристическая проверка длины основы. Окончание удаляется только в том случае, если оставшаяся часть слова (основа) длиннее 4 байт (2-х русских букв). Это исключило ложные срабатывания на коротких словах.

    \item \textbf{Проблема: Падение производительности при стемминге.}
    Внедрение стеммера Портера снизило скорость индексации с 24 МБ/с до 0.7 МБ/с. Профилирование показало, что узким местом является создание объектов \texttt{std::regex} внутри цикла обработки миллионов слов.
    
    \textbf{Решение:} Для лабораторной работы данная скорость признана приемлемой (обработка корпуса занимает около 2 минут). В отчете зафиксировано, что для production-решений необходимо заменить \texttt{std::regex} на прямые строковые проверки (метод суффиксов), что подтверждается тестами производительности без стемминга.
\end{enumerate}

\subsection{План тестирования}

Для верификации корректности работы алгоритмов был разработан модуль модульного тестирования (Unit Testing). Вместо использования сторонних фреймворков (GTest), был написан собственный легковесный \texttt{TestRunner}, позволяющий проверять утверждения (\texttt{AssertEqual}) и выводить результаты в консоль.

Был создан отдельный исполняемый файл \texttt{run\_tests.exe}, выполняющий следующие группы тестов:

\textbf{Тест-кейс №1. Структуры данных (CustomMap Stress Test).}
\begin{itemize}
    \item \textbf{Цель:} Проверить корректность работы собственной хеш-таблицы при возникновении коллизий.
    \item \textbf{Сценарий:} Создается таблица малого размера (10 корзин). В нее добавляется 100 различных ключей (\texttt{key\_0} ... \texttt{key\_99}). Гарантированно возникают коллизии.
    \item \textbf{Проверка:} Проверяется, что все 100 ключей доступны для чтения и имеют корректные значения. Проверяется корректность инкремента значений.
    \item \textbf{Результат:} \texttt{[ OK ]}. Метод цепочек работает корректно, данные не теряются.
\end{itemize}

\textbf{Тест-кейс №2. Лингвистический анализ (Stemmer Extended Russian).}
\begin{itemize}
    \item \textbf{Цель:} Проверить корректность работы стеммера Портера для различных частей речи.
    \item \textbf{Сценарий:} На вход подаются пары «Исходное слово» — «Ожидаемая основа».
    \item \textbf{Проверки:}
    \begin{itemize}
        \item Глаголы прошедшего времени: \textit{«бегал» $\rightarrow$ «бег»}, \textit{«смотрела» $\rightarrow$ «смотр»} (удаление суффиксов -ал, -ела).
        \item Существительные во мн. числе и падежах: \textit{«компьютеры» $\rightarrow$ «компьютер»}, \textit{«окнами» $\rightarrow$ «окн»}.
        \item Прилагательные: \textit{«красный» $\rightarrow$ «красн»}.
        \item Защита коротких слов: \textit{«дом» $\rightarrow$ «дом»} (не обрезается до «д»).
    \end{itemize}
    \item \textbf{Результат:} \texttt{[ OK ]}. Алгоритм корректно обрабатывает основные правила русского языка.
\end{itemize}

\textbf{Тест-кейс №3. Токенизация и UTF-8.}
\begin{itemize}
    \item \textbf{Цель:} Проверить корректность разбиения текста и перевода в нижний регистр.
    \item \textbf{Сценарий:} Обработка строки со смешанным регистром и знаками препинания: \textit{«ПрИвЕт, Мир!»}.
    \item \textbf{Проверка:} Ожидается получение двух чистых токенов: \textit{«привет»} и \textit{«мир»}. Знаки препинания должны быть удалены.
    \item \textbf{Результат:} \texttt{[ OK ]}.
\end{itemize}

\subsection{Изображения}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{график.png}
    \caption{График распределения}
    \label{fig:graf}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{вывод_статистик.png}
    \caption{Вывод статистик}
    \label{fig:stats}
\end{figure}

\subsection{Выводы}

В ходе выполнения лабораторной работы был успешно реализован и протестирован модуль лингвистической обработки текста, являющийся фундаментом для построения поискового индекса.

\textbf{Основные результаты:}
\begin{enumerate}
    \item \textbf{Собственная реализация структур данных.} В соответствии с техническим заданием, частотный словарь был построен без использования готовых хеш-таблиц STL (\texttt{std::map}). Реализация \texttt{CustomMap} на базе \texttt{std::vector} с разрешением коллизий методом цепочек показала высокую эффективность и корректную работу под нагрузкой.
    
    \item \textbf{Подтверждение закона Ципфа.} Статистический анализ корпуса подтвердил, что распределение частот слов подчиняется степенному закону,  доказывает валидность собранных данных. Выявленные отклонения горб в средней части графика корректно объясняются спецификой предметной области насыщенность юридическими и деловыми терминами.
    
    \item \textbf{Эффективность сжатия словаря.} Внедрение стемминга Портера дало сократить количество уникальных терминов на \textbf{48.5\%} (с 146 471 до 75 531). Это существенно снизит потребление памяти при построении инвертированного индекса в следующей работе и повысит полноту поиска за счет объединения грамматических форм слов.
\end{enumerate}

\textbf{Критический анализ и недостатки:}
Основным выявленным недостатком является \textbf{низкая производительность модуля стемминга} в текущей реализации.
\begin{itemize}
    \item \textbf{Проблема:} Использование стандартной библиотеки \texttt{std::regex} для реализации правил усечения окончаний снизило скорость индексации с 24 МБ/с до 0.7 МБ/с (замедление в 34 раза). Это делает текущую реализацию непригодной для обработки гигабайтных массивов данных в реальном времени.
    \item \textbf{Способ устранения:} Для оптимизации необходимо отказаться от регулярных выражений в пользу прямых строковых операций (проверка суффиксов через сравнение символов). Это усложнит код поддержки правил, но позволит вернуть скорость обработки к показателям 15–20 МБ/с без потери качества лингвистического анализа.
\end{itemize}

Разработанный программный модуль функционально готов к интеграции в поисковую систему.


\newpage
\section{Лабораторная работа №4. Индексация и булев поиск}

\subsection{Задание}
Целью работы является разработка полнотекстовой поисковой системы, поддерживающей сложные булевы запросы. Работа состоит из двух этапов: построения бинарного индекса и реализации механизма поиска.

\textbf{Этап 1. Построение индекса}
Требуется построить поисковый индекс по корпусу документов, подготовленному в Лабораторной работе №1.

\textbf{Требования к индексу:}
\begin{itemize}
    \item \textbf{Бинарный формат.} Использование текстовых форматов (JSON, XML) или готовых баз данных (SQLite, MongoDB) \textbf{запрещено}. Формат хранения данных должен быть разработан самостоятельно и описан в отчете в побайтовом представлении.
    \item \textbf{Расширяемость.} Формат должен предполагать возможность добавления новых полей в будущем.
    \item \textbf{Структура.} Необходимо создать два типа индексов:
    \begin{enumerate}
        \item \textit{Обратный индекс} — для поиска документов по терминам.
        \item \textit{Прямой индекс} — для хранения метаданных (заголовки, ссылки) и генерации страницы выдачи.
    \end{enumerate}
    \item \textbf{Препроцессинг.} Для всех термов должна быть выполнена токенизация и понижение регистра.
\end{itemize}

\textbf{Этап 2. Реализация булева поиска}
Необходимо реализовать ввод поисковых запросов, их парсинг и выполнение над построенным индексом.

\textbf{Синтаксис поисковых запросов:}
\begin{itemize}
    \item \textbf{AND (И):} Пробел или оператор \texttt{\&\&}.
    \item \textbf{OR (ИЛИ):} Оператор \texttt{||}.
    \item \textbf{NOT (НЕТ):} Оператор \texttt{!}.
    \item \textbf{Группировка:} Поддержка круглых скобок \texttt{( )}.
\end{itemize}
\textit{Требование:} Парсер должен быть устойчив к переменному числу пробелов и валидировать структуру запроса.

\textbf{Интерфейс системы:}
\begin{enumerate}
    \item \textbf{Веб-сервис.} Должен реализовывать базовую функциональность:
    \begin{itemize}
        \item Начальная страница с формой ввода.
        \item Страница выдачи: 50 результатов на страницу, заголовки документов, пагинация (кнопка «Следующие 50»).
    \end{itemize}
    \item \textbf{CLI-утилита.} Утилита командной строки, принимающая файл с запросами и выполняющая поиск в пакетном режиме.
\end{enumerate}

\textbf{В отчете необходимо представить:}
\begin{itemize}
    \item Описание выбранного метода сортировки (BSBI/SPIMI), его достоинства и недостатки.
    \item Статистику индексации: количество термов, средняя длина терма (сравнение с токеном из ЛР3).
    \item Анализ производительности: скорость индексации (общая, на документ, на КБ).
    \item Анализ масштабируемости: оценка поведения системы при увеличении объема данных в 10, 100, 1000 раз.
    \item Скорость выполнения поисковых запросов.
    \item Примеры сложных запросов и методика тестирования корректности выдачи.
\end{itemize}

\subsection{Краткое описание метода решения задачи}

Решение задачи разделено на два независимых этапа: построение индекса (Indexing) и выполнение поисковых запросов. Для реализации использован язык C++ для backend-логики и Python (Streamlit) для веб-интерфейса.

\subsubsection{Структура и формат индекса}
В соответствии с требованием задания, был разработан собственный бинарный формат хранения данных. Отказ от текстовых форматов (JSON/XML) и готовых БД позволил минимизировать размер индекса и обеспечить мгновенную скорость чтения.

Создаются два бинарных файла:

\textbf{А. Прямой индекс (\texttt{docs\_index.bin})}
Служит для быстрого получения метаданных документа заголовка по его числовому идентификатору (\texttt{DocID}).
\begin{itemize}
    \item \textbf{Header:}
    \begin{itemize}
        \item \texttt{Signature} (4 байта): Магическое число \texttt{0x53434F44} ("DOCS") для валидации файла.
        \item \texttt{Count} (4 байта, \texttt{uint32}): Количество документов $N$.
    \end{itemize}
    \item \textbf{Body (Записи идут подряд):}
    \begin{itemize}
        \item \texttt{TitleLen} (2 байта, \texttt{uint16}): Длина заголовка в байтах.
        \item \texttt{Title} ($K$ байт): Строка заголовка в UTF-8.
        \item \texttt{Reserved} (2 байта): Зарезервировано для длины URL.
    \end{itemize}
\end{itemize}

\textbf{Б. Обратный индекс (\texttt{inverted\_index.bin})}
Связывает каждый термин со списком документов, в которых он встречается. Состоит из словаря и блоков данных постингов.
\begin{itemize}
    \item \textbf{Header:}
    \begin{itemize}
        \item \texttt{Signature} (4 байта): \texttt{0x5A584449} ("IDXZ").
        \item \texttt{Version} (1 байт): Версия формата (0x01).
        \item \texttt{TermCount} (4 байта): Количество уникальных терминов.
    \end{itemize}
    \item \textbf{Dictionary (Словарь):}
    \begin{itemize}
        \item \texttt{TermLen} (1 байт): Длина термина.
        \item \texttt{Term} ($L$ байт): Сама строка термина.
        \item \texttt{DocFreq} (4 байта): Количество документов, содержащих термин.
        \item \texttt{Offset} (4 байта): Смещение в байтах от начала файла до списка \texttt{DocID}.
    \end{itemize}
    \item \textbf{Списки вхождения:}
    \begin{itemize}
        \item Массив \texttt{DocID} (4 байта каждый), расположенный по смещению \texttt{Offset}.
    \end{itemize}
\end{itemize}

\subsubsection{Алгоритм индексации (BSBI)}
Для построения индекса был выбран подход, основанный на сортировке блоков, адаптированный для работы в оперативной памяти.

\textbf{Этапы работы (\texttt{src/indexer.cpp}):}
\begin{enumerate}
    \item \textbf{Сбор пар.} Программа обходит корпус документов. Каждый документ токенизируется и стеммируется. Формируется список пар: $\langle Term, DocID \rangle$.
    \item \textbf{Сортировка.} Полученный массив пар (более 4.5 млн записей) сортируется в лексикографическом порядке по терминам, а затем по возрастанию DocID.
    \begin{itemize}
        \item \textit{Выбранный метод сортировки:} \texttt{std::sort} (Introsort — гибрид QuickSort, HeapSort и InsertionSort).
        \item \textit{Достоинства:} Высокая скорость $O(N \log N)$, отсутствие накладных расходов на сложные структуры данных (деревья).
        \item \textit{Недостатки:} Требует загрузки всех пар в оперативную память. При превышении объема RAM метод перестанет работать (см. анализ масштабируемости).
    \end{itemize}
    \item \textbf{Сжатие и запись.} Проход по отсортированному массиву. Одинаковые термины объединяются, формируя список постингов. Словарь и списки записываются в бинарный файл.
\end{enumerate}

\subsubsection{Реализация поиска}
Поисковый движок (\texttt{src/search\_engine.cpp}) загружает словарь в память (хеш-таблица \texttt{DictionaryMap}), но списки \texttt{DocID} читает с диска по требованию (через \texttt{seek} по \texttt{Offset}), что экономит память.

\textbf{Парсинг запросов:}
Использован алгоритм \textbf{сортировочной станции} Дейкстры.
\begin{itemize}
    \item Запрос вида \texttt{(A || B) \&\& !C} преобразуется в Обратную Польскую Нотацию (RPN): \texttt{A B || C ! \&\&}.
    \item Поддерживаются операторы: \texttt{AND} (пересечение), \texttt{OR} (объединение), \texttt{NOT} (разность множеств), приоритет скобок.
\end{itemize}

\textbf{Выполнение:}
RPN исполняется на стеке. Операции над множествами (\texttt{intersect}, \texttt{union}) реализованы линейно за $O(N+M)$, так как списки \texttt{DocID} в индексе гарантированно отсортированы.

\subsection{Результаты и анализ}

\subsubsection{Статистика индекса}
\begin{itemize}
    \item \textbf{Количество документов:} 40 823.
    \item \textbf{Количество уникальных термов:} 75 257.
    \item \textbf{Средняя длина терма:} 15.41 байт.
\end{itemize}

\textbf{Сравнительный анализ длины терма:}
В ЛР3 средняя длина токена составляла 10.0 байт, а в ЛР4 средняя длина терма в индексе — 15.4 байт.
\textit{Причина отличия:}
\begin{itemize}
    \item В ЛР3 статистика считалась по \textbf{потоку текста}. В тексте частота коротких служебных слов (союзы, предлоги длиной 2-4 байта) огромна, тянет среднее значение вниз.
    \item В ЛР4 статистика считается по \textbf{словарю уникальных слов}. В словаре каждое слово (и короткий предлог «и», и длинное слово «административный») представлено один раз. Согласно закону Ципфа, длинных низкочастотных слов в языке больше, поэтому средняя длина словаря всегда выше средней длины текста.
\end{itemize}

\subsubsection{Анализ производительности и масштабируемости}

\textbf{Скорость индексации:}
\begin{itemize}
    \item Общее время: $\approx$ 462 сек.
    \item Скорость (Data Throughput): \textbf{0.19 МБ/с}.
    \item Скорость (Per Document): \textbf{11.3 мс/док}.
\end{itemize}

\textbf{Оценка оптимальности:}
Текущая скорость является \textbf{неоптимальной}. Основной ограничивающий фактор — использование \texttt{std::regex} в процедуре стемминга, которая вызывается для каждого из 7 млн слов.
\textit{Способ ускорения:} Замена регулярных выражений на примитивные строковые операции проверки суффиксов (\texttt{std::string::ends\_with}) позволит увеличить скорость в 20–30 раз (до 5–10 МБ/с).

\textbf{Анализ масштабируемости:}
\begin{enumerate}
    \item \textbf{Рост в 10 раз (400 тыс. доков):} 
    Время индексации составит $\approx$ 80 минут. Потребуется около 4-6 ГБ оперативной памяти для хранения вектора пар $\langle Term, DocID \rangle$. 
    
    \item \textbf{Рост в 100 раз (4 млн доков):} 
    Потребуется $\approx$ 50 ГБ RAM. Произойдет переполнение памяти (\texttt{std::bad\_alloc}), процесс аварийно завершится.
    \textit{Решение:} Переход от In-Memory сортировки к алгоритму \textbf{SPIMI} (Single-Pass In-Memory Indexing). Индекс строится кусками, которые сбрасываются на диск, а затем объединяются в итоговый файл.
    
    \item \textbf{Рост в 1000 раз (40 млн доков):} 
    Время индексации на одной машине составит недели. 
    \textit{Решение:} Переход к распределенной индексации, шардирование индекса по нескольким серверам.
\end{enumerate}

\subsubsection{Скорость поиска}
Скорость выполнения поисковых запросов составляет \textbf{< 1 мс} (от 0.05 до 0.5 мс в зависимости от сложности запроса). 

\subsection{Журнал выполнения задания}

В ходе разработки поискового движка и интеграции его компонентов возник ряд технических проблем. Ниже приведено описание возникших ошибок и примененных методов их устранения.

\begin{enumerate}
    \item \textbf{Проблема: Ошибки линковки (LNK2019 Unresolved External Symbol).}
    При попытке компиляции модуля поиска (\texttt{lab4\_search}) компоновщик не мог найти реализацию методов класса \texttt{SearchEngine}, хотя заголовочные файлы были подключены корректно.
    
    \textbf{Причина:} В конфигурации \texttt{CMakeLists.txt} для цели \texttt{lab4\_search} не был указан файл реализации \texttt{src/search\_engine.cpp}.
    
    \textbf{Решение:} Скорректирован файл сборки CMake. Все зависимые \texttt{.cpp} файлы добавлены в директиву \texttt{add\_executable}.

    \item \textbf{Проблема: Тестирование приватных методов (Error C2352).}
    При написании модульных тестов для булевой логики (\texttt{intersect}, \texttt{union}) возникла ошибка вызова нестатической функции-члена без объекта класса. Создавать тяжеловесный объект \texttt{SearchEngine} который требует загрузки индекса с диска для проверки простой математики множеств было нецелесообразно.
    
    \textbf{Решение:} Методы, реализующие теоретико-множественные операции, были объявлены как \texttt{public static}. сделал их чистыми функциями, не зависящими от состояния объекта, позволило тестировать их изолированно.

    \item \textbf{Проблема: Конфликт типов в шаблонах тестов (Error C2672).}
    Шаблонная функция утверждения \texttt{AssertEqual} требовала строгого совпадения типов аргументов. При сравнении результата метода \texttt{vector::size()} (тип \texttt{size\_t}) с числовым литералом (тип \texttt{int}) возникала ошибка компиляции.
    
    \textbf{Решение:} В код тестов добавлено явное приведение типов (\texttt{static\_cast<int>}), либо использование литералов соответствующего типа (суффикс \texttt{ULL}).

    \item \textbf{Проблема: Интеграция C++ backend и Python frontend.}
    При запуске веб-интерфейса процесс C++ аварийно завершался с кодом ошибки, не успевая передать JSON-ответ.
    
    \textbf{Причина:} Проблема относительных путей. Python запускал \texttt{.exe} файл из папки \texttt{Release}, и C++ программа пыталась искать индексы по пути \texttt{../../index\_data}, который оказывался неверным относительно бинарного файла.
    
    \textbf{Решение:} В Python-скрипте (\texttt{subprocess.Popen}) явно задан параметр \texttt{cwd} (Current Working Directory), указывающий на корневую папку сборки, восстановил корректность относительных путей.
\end{enumerate}

\subsection{План тестирования}

Для проверки работоспособности системы применялся комбинированный подход: модульное тестирование (Unit Testing) отдельных алгоритмов и интеграционное тестирование готового поискового механизма.

\subsubsection{Модульные тесты (C++)}
Использован разработанный ранее фреймворк \texttt{TestRunner}.

\textbf{Тест-кейс №1. Парсер запросов.}
\begin{itemize}
    \item \textbf{Цель:} Проверить корректность преобразования инфиксной записи запроса в Обратную Польскую Нотацию (RPN) с учетом приоритетов.
    \item \textbf{Сценарии:}
    \begin{itemize}
        \item Приоритет операторов: \texttt{A || B \&\& C} $\rightarrow$ должно интерпретироваться как \texttt{A || (B \&\& C)}. Результат RPN: \texttt{A B C \&\& ||}.
        \item Обработка скобок: \texttt{(A || B) \&\& C} $\rightarrow$ приоритет меняется. Результат RPN: \texttt{A B || C \&\&}.
        \item Сложный запрос с NOT: \texttt{Москва !метро} $\rightarrow$ \texttt{Москва метро ! \&\&}.
    \end{itemize}
    \item \textbf{Результат:} \texttt{[ OK ]}. Парсер корректно строит дерево разбора.
\end{itemize}

\textbf{Тест-кейс №2. Булева алгебра.}
\begin{itemize}
    \item \textbf{Цель:} Проверить математическую корректность операций над списками DocID.
    \item \textbf{Входные данные:} Множество $A = \{1, 5, 10, 20\}$, Множество $B = \{5, 8, 10, 100\}$.
    \item \textbf{Проверки:}
    \begin{itemize}
        \item \texttt{INTERSECT (AND)}: Ожидается $\{5, 10\}$.
        \item \texttt{UNION (OR)}: Ожидается $\{1, 5, 8, 10, 20, 100\}$ (сортировка сохранена).
        \item \texttt{DIFFERENCE (NOT)}: $A \setminus B$. Ожидается $\{1, 20\}$.
        \item \textbf{Граничные случаи:} Пересечение с пустым множеством должно давать пустое множество.
    \end{itemize}
    \item \textbf{Результат:} \texttt{[ OK ]}. Алгоритмы работают линейно и корректно.
\end{itemize}

\subsubsection{Интеграционное тестирование}
Проводилось через веб-интерфейс и CLI.

\textbf{Тест-кейс №3. Поиск по реальным данным.}
\begin{itemize}    
    \item \textbf{Запрос:} \texttt{(закон || право) \&\& !налог}
    \item \textbf{Цель:} Проверить работу исключения.
    \item \textbf{Результат:} Найдено 13 504 документа. При ручном просмотре топ-20 результатов ни в одном заголовке не найдено слово «налог», при этом присутствуют юридические термины.
    
    \item \textbf{Запрос:} \texttt{москва \&\& (авиация || космос)}
    \item \textbf{Результат:} Найден 1 документ («5 причин перевести свой бизнес в ОЭЗ»). Это подтверждает высокую точность обработки вложенной логики.
\end{itemize}

\textbf{Тест-кейс №4. Валидация отображения контента.}
\begin{itemize}
    \item \textbf{Действие:} Клик по заголовку найденного документа в веб-интерфейсе.
    \item \textbf{Ожидаемый результат:} Должен развернуться блок с полным текстом статьи, загруженным с локального диска (\texttt{corpus\_txt}).
    \item \textbf{Результат:} Текст отображается корректно, кодировка UTF-8 не нарушена.
\end{itemize}

\subsection{Изображения}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{поиск.png}
    \caption{Результаты поиска по запросу}
    \label{fig:serch}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{поиск2.png}
    \caption{Результаты поиска по запросу}
    \label{fig:serch2}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{поиск3.png}
    \caption{WEB UI}
    \label{fig:serch3}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{поиск4.png}
    \caption{WEB UI}
    \label{fig:serch4}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{поиск5.png}
    \caption{WEB UI}
    \label{fig:serch5}
\end{figure}

\subsection{Выводы}

В рамках лабораторной работы была успешно решена задача построения полнотекстовой поисковой системы с поддержкой булевой логики. 

\textbf{Ключевые результаты:}
\begin{enumerate}
    \item \textbf{Бинарный формат индекса.} Разработан собственный расширяемый формат хранения данных. Разделение на прямой и обратный индексы позволило минимизировать накладные расходы на чтение. Доступ к словарю осуществляется за $O(1)$, а списки вхождений подгружаются с диска только по требованию (\texttt{seek}).
    
    \item \textbf{Алгоритмы поиска.} Реализация парсера на базе алгоритма сортировочной станции и линейных операций над множествами (\texttt{intersect}, \texttt{union}) обеспечила время отклика системы \textbf{менее 1 мс} на запрос. 
    
    \item \textbf{Точность и гибкость.} Система корректно обрабатывает сложные вложенные запросы с приоритетом операций (скобки) и оператором отрицания. Интеграция стемминга (из ЛР3) позволяет находить документы независимо от словоформы запроса.
\end{enumerate}

\textbf{Критический анализ и направления для оптимизации:}
\begin{itemize}
    \item \textbf{Узкое место при индексации.} Скорость построения индекса (0.19 МБ/с) ограничена производительностью стеммера на регулярных выражениях. 
    
    \item \textbf{Потребление памяти (BSBI).} Текущий алгоритм индексации сортирует пары $\langle Term, DocID \rangle$ в оперативной памяти. При увеличении объема корпуса в 100 раз до 4 млн документов это приведет к переполнению RAM.
    \textit{Необходимая доработка:} Внедрение алгоритма \textbf{SPIMI}, который записывает временные блоки на диск и выполняет их слияние, что позволит индексировать коллекции любого размера, ограниченные только местом на жестком диске.
\end{itemize}

\newpage
\section*{Список использованных источников}
\addcontentsline{toc}{section}{Список использованных источников}
\begingroup
\renewcommand{\section}[2]{} % Скрываем заголовок thebibliography, так как мы сделали свой \section*
\begin{thebibliography}{99}

\bibitem{manning}
\textit{Маннинг К., Рагхаван П., Шютце Х.} Введение в информационный поиск. — М.: Вильямс, 2011. — 528 с.

\bibitem{knuth}
\textit{Кнут Д. Э.} Искусство программирования. Том 3. Сортировка и поиск. — 2-е изд. — М.: Вильямс, 2007. — 824 с.

\bibitem{zipf_wiki}
Закон Ципфа [Электронный ресурс] // Рувики : свободная энциклопедия. — Режим доступа: \url{https://ru.ruwiki.ru/wiki/Закон_Ципфа} (дата обращения: 18.12.2025).

\bibitem{zipf_netology}
Что такое закон Ципфа и как он работает в SEO [Электронный ресурс] // Нетология : блог. — Режим доступа: \url{https://netology.ru/blog/02-2019-zakon-cipfa-vydacha} (дата обращения: 18.12.2025).

\bibitem{mitup_ir}
Теоретические основы информационного поиска [Электронный ресурс] // AI Mitup : журнал. — Режим доступа: \url{https://ai.mitup.ru/journal/referat/teoreticheskie-osnovy-informaczionnogo-poiska/} (дата обращения: 18.12.2025).

\bibitem{habr_yandex}
Как устроен поиск: архитектура и ранжирование [Электронный ресурс] // Хабр. — Режим доступа: \url{https://habr.com/ru/companies/yandex/articles/464375/} (дата обращения: 18.12.2025).

\bibitem{habr_search_arch}
Архитектура поисковых систем: от краулера до индекса [Электронный ресурс] // Хабр. — Режим доступа: \url{https://habr.com/ru/articles/100098/} (дата обращения: 18.12.2025).

\bibitem{habr_boolean}
Реализация алгоритмов булева поиска и инвертированного индекса [Электронный ресурс] // Хабр. — Режим доступа: \url{https://habr.com/ru/articles/946764/} (дата обращения: 18.12.2025).

\bibitem{so_crawler}
How to write a crawler [Электронный ресурс] // Stack Overflow. — Режим доступа: \url{https://stackoverflow.com/questions/102631/how-to-write-a-crawler} (дата обращения: 18.12.2025).

\bibitem{cpp_ref}
C++ Reference documentation [Электронный ресурс] // CppReference. — Режим доступа: \url{https://en.cppreference.com/w/} (дата обращения: 18.12.2025).

\bibitem{postgres}
PostgreSQL 15 Documentation [Электронный ресурс] // PostgreSQL Global Development Group. — Режим доступа: \url{https://www.postgresql.org/docs/15/index.html} (дата обращения: 18.12.2025).

\bibitem{bs4}
Beautiful Soup 4 Documentation [Электронный ресурс] // Crummy.com. — Режим доступа: \url{https://www.crummy.com/software/BeautifulSoup/bs4/doc/} (дата обращения: 18.12.2025).

\end{thebibliography}
\endgroup

\end{document}